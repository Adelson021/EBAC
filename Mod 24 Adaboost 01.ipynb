{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f8b0af2-e8e8-4b65-9002-35473fe7e197",
   "metadata": {},
   "source": [
    "**1. Diferenças entre Random Forest e AdaBoost**  \n",
    "\n",
    "Estrutura dos Modelos: O Random Forest utiliza múltiplas árvores de decisão independentes, criando uma floresta de árvores que fazem previsões de maneira paralela, enquanto o AdaBoost usa um conjunto sequencial de estimadores, onde cada modelo é ajustado para corrigir erros dos anteriores.  \n",
    "\n",
    "Peso das Instâncias: No AdaBoost, instâncias de dados incorretamente classificadas recebem pesos maiores a cada iteração para que os classificadores subsequentes foquem nesses casos difíceis. O Random Forest, por outro lado, usa amostras bootstrap e atribui pesos iguais a todas as observações.  \n",
    "\n",
    "Ensemble de Modelo Base: No Random Forest, o modelo base é tipicamente uma árvore de decisão completa, enquanto no AdaBoost, o modelo base é geralmente uma \"árvore fraca\" (stump), ou seja, uma árvore de decisão com apenas um nó.  \n",
    "\n",
    "Robustez a Overfitting: O Random Forest tende a ser mais robusto contra overfitting devido à combinação de amostragem bootstrap e aleatoriedade na escolha de variáveis para cada nó. Já o AdaBoost é mais suscetível a overfitting em datasets com muito ruído, pois tenta se ajustar a cada ponto de dado.  \n",
    "\n",
    "Agregação de Resultados: No Random Forest, a previsão final é feita pela média (para regressão) ou votação (para classificação) das previsões das árvores. No AdaBoost, os classificadores têm diferentes pesos com base em sua precisão, e o modelo final é a combinação ponderada dos estimadores.  \n",
    "\n",
    "**2. Código do AdaBoost no Jupyter Notebook**\n",
    "  \n",
    "Vou criar um exemplo básico de AdaBoost usando o dataset load_iris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa9390b2-e7a1-47da-85dc-5abaa67e4685",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia do modelo AdaBoost: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Importando as bibliotecas\n",
    "import warnings\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Suprimir todos os avisos\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Carregando o dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Dividindo os dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Treinando o modelo AdaBoost\n",
    "clf = AdaBoostClassifier(n_estimators=50, learning_rate=1.0, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Avaliando o modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Acurácia do modelo AdaBoost: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ab7db0-e987-4490-9001-29f8a4827223",
   "metadata": {},
   "source": [
    "Esse código realiza o treinamento de um modelo AdaBoost no conjunto de dados load_iris e exibe a acurácia no conjunto de teste.\n",
    "\n",
    "**3. Hiperparâmetros Importantes no AdaBoost**  \n",
    "\n",
    "n_estimators: Número de estimadores fracos no conjunto. Controla o número de iterações do treinamento.  \n",
    "learning_rate: Taxa de aprendizado que reduz o peso dos estimadores a cada iteração. Afeta o ajuste do modelo.  \n",
    "base_estimator: Modelo base usado, como uma árvore de decisão fraca (árvore stump). Pode ser ajustado para outros estimadores.  \n",
    "random_state: Controla a aleatoriedade para tornar o treinamento reproduzível.  \n",
    "algorithm: Define o algoritmo de aumento. As opções são SAMME ou SAMME.R, onde SAMME.R usa pesos reais e geralmente fornece uma melhor performance.  \n",
    "\n",
    "**4. Otimização com GridSearch (Opcional)**  \n",
    "\n",
    "Para realizar uma busca por melhores hiperparâmetros com GridSearchCV, você pode usar o código abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06c836a9-0366-47fb-a7a4-3f77ad8bff59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhores parâmetros: {'algorithm': 'SAMME', 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "Acurácia do modelo otimizado: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definindo os parâmetros para o GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'learning_rate': [0.01, 0.1, 1, 10],\n",
    "    'algorithm': ['SAMME', 'SAMME.R']\n",
    "}\n",
    "\n",
    "# Configurando o GridSearchCV\n",
    "grid_search = GridSearchCV(AdaBoostClassifier(random_state=42), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Melhor combinação de hiperparâmetros\n",
    "print(\"Melhores parâmetros:\", grid_search.best_params_)\n",
    "\n",
    "# Avaliação com os melhores parâmetros\n",
    "y_pred_optimized = grid_search.predict(X_test)\n",
    "accuracy_optimized = accuracy_score(y_test, y_pred_optimized)\n",
    "print(f\"Acurácia do modelo otimizado: {accuracy_optimized:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79818234-6d34-4e40-867e-0ecb297c7f1f",
   "metadata": {},
   "source": [
    "Esse código irá realizar uma busca exaustiva pelos melhores hiperparâmetros no modelo AdaBoost usando o GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5187e6ad-0397-42a3-bf29-feefd63145db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
